#!/usr/bin/env python3

# Copyright (c) 2021, Hugh Leather
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

import os
import argparse
from pathlib import Path
import csv

import logging

from typing import Iterable, Optional, Tuple

from mptools import init_signals, default_signal_handler, MainContext

from augmentum.__about__ import __version__

from augmentum.sysUtils import check_arg_list

from augmentum.sysProg import InstrumentationScope, SysProg

from augmentum.benchmarks import BenchmarkFactory

from augmentum.objectives import CodeSizeObjective

from augmentum.functionfilter import InstrumentDefault, InstrumentFunctionList

from augmentum.targetfilter import TargetFilter

from augmentum.driver import Driver
from augmentum.mplogging import LogListener, configure_root_logging

from augmentum.augmentumUtils import (
    load_evaluation_config, setup_root_directory, setup_working_directories
)

from augmentum.sysUtils import KVListAction

logger = logging.getLogger(__name__)

def load_target_functions(tfn_file : Iterable[str], chunk_size : Optional[int],
                          chunk_offset : Optional[int]) -> Optional[Iterable[Tuple[str,str]]] :
    """Load specified chunk of target functions from specified file."""
    if not tfn_file:
        return None

    reader = csv.reader(tfn_file, delimiter=';')
    next(reader, None)  # skip the headers
    tfn_entries = [(row[0],row[1]) for row in reader]

    if (chunk_size and chunk_offset is None) or (chunk_size is None and chunk_offset):
        raise RuntimeError("--fn_chunk_size and --fn_chunk_offset "
                           "must both be used or none of them.")

    if chunk_size is not None and chunk_offset is not None:
        start = chunk_offset * chunk_size
        end = start + chunk_size
        if start >= len(tfn_entries):
            logger.warning("Target function offset too high, nothing to do!")
            return []
        if end >= len(tfn_entries): # return rest
            return tfn_entries[start:]
        else: # return selected chunk
            return tfn_entries[start:end]
    else:
        return tfn_entries

def parse_args():
    """Specification and parsing of command line arguments."""
    parser = argparse.ArgumentParser(
        description="Driver to evaluate priors for target functions in a specified system program.")
    parser.add_argument("--run_id", metavar="ID", type=str,
                        required=True, help="ID used to identify this evaluation execution.")
    parser.add_argument("--working_dir", metavar="DIR", type=Path,
                        required=True, help="Directory for generated data.")
    parser.add_argument("--config",  metavar="JSON", type=argparse.FileType('r'),
                        required=True, help="Json file with evaluation configuration.")
    parser.add_argument("--heuristicDB", metavar="URL", type=str,
                        help="SQL DB indicating previously collected information about heuristic statistics.")
    parser.add_argument("--function_cache", metavar="FILE", type=Path, help="File path to target function cache. "
                        "If file does not exist, a cache will be create after colleting functions.")
    parser.add_argument("--baseline_cache", metavar="FILE", type=Path, help="File path to baseline statistics cache. "
                        "If file does not exist, a cache will be create after measuring baselines.")

    parser.add_argument('--bmark_filter', metavar="SUITE#B1,B2,B3...", nargs='*', type=str, action=KVListAction,
                        help="List of manually specified benchmarks using key value lists "
                        "<suite#name1,name2,name3>, e.g. POLYBENCH#correlation,lu")

    parser.add_argument("--target_functions", metavar="FILE", type=argparse.FileType('r'),
                            help="A specific list of target function names to be instrumented.")
    parser.add_argument("--target_filter", metavar="FILE", type=argparse.FileType('r'),
                            help="A specific list with block and allow rules for evaluation targets.")
    parser.add_argument("--fn_chunk_size", metavar="SIZE", type=int,
                            help="Number of functions to be evaluated by this evaluation run. (considered only if --target_functions is used)")
    parser.add_argument("--fn_chunk_offset", metavar="OFFSET", type=int,
                            help="Start offset for functions to be evaluated. (considered only if --target_functions is used)")

    parser.add_argument("--instr_scope", metavar="VALUE", type=lambda scope: check_arg_list(
                            parser, scope, ["PATH","FUNCTION","MODULE","ALL"], "Invalid instrumentation scope!"),
                            default="FUNCTION", help="Scope of instrumentation to be used [FUNCTION, MODULE, ALL].")
    parser.add_argument("--instr_chunk", metavar="VALUE", type=int, default=1,
                            help="Chunk size of for instrumentation scope.")

    parser.add_argument("--keep_probes", action='store_true',
                        help="Keep probe code and probe folders around. ATTENTION: disk space intensive for long runs.")

    parser.add_argument("--cpus", metavar="VALUE", type=int,
                        help="Number of available CPUs for this run.")
    parser.add_argument("--worker_mul", metavar="VALUE", type=float, default=1.0,
                        help="Number of workers is the configured cpus times this multiplier.")
    parser.add_argument("--exact_cpu_map", action='store_true',
                        help="If this flag is active, workers and main thread are mapped exactly to the number of cpus."
                        " worker_mul flag is ignored and cpus has to be larger 1.")
    parser.add_argument("--probe_mem_limit", metavar="VALUE", type=float, default=None,
                        help="Memory limit in MB granted to each probe compilation and probe run.")
    parser.add_argument("--loglevel", metavar="LEVEL", type=str, default="INFO",
                        help="Configure log level.")
    parser.add_argument("--dry_run", action='store_true',
                        help="If this flag is active, the amount of work left to do for the given configuration is evaluated and no analysis is executed.")
    parser.add_argument("--skip_immutables", action='store_true',
                        help="If this flag is active, immutable function parameter paths are skipped after Null Prior.")
    parser.add_argument("--independent_test_cases", action='store_true', default=False,
                        help="If this flag is active, test cases are considered as independent applications.")                        
    parser.add_argument("--no_instr", action='store_true',
                        help="Deactivate instrumentation for debugging purposes.")
    parser.add_argument("--record_exec_log", action='store_true',
                        help="If active, all probed values are stored in the database.")
    parser.add_argument("-v","--verbose", action='store_true', help="Activate verbose program output.")
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_args()

    general_cfg, tools_cfg, sysprog_cfg, benchmark_cfgs = load_evaluation_config(args.config)

    wd_run = setup_root_directory(args.run_id, args.working_dir)

    # setup two main contexts to keep logging running during shutdown of the worker context
    with MainContext() as log_ctx:
        init_signals(log_ctx.shutdown_event, default_signal_handler, default_signal_handler)

        # configure logging
        log_q = log_ctx.MPQueue()
        log_ctx.Proc("LOG_LISTENER", LogListener, log_q, wd_run / "run.log", args.loglevel)
        configure_root_logging(log_q, args.loglevel)

        if 'HOSTNAME' in os.environ:
            host = os.environ['HOSTNAME']
        else:
            host = "localhost"
        logger.info(f"Running function analyser {__version__} on host {host}")
        logger.info("Setting up working directory at: " + str(wd_run) + "...")

        with MainContext() as main_ctx:
            init_signals(main_ctx.shutdown_event, default_signal_handler, default_signal_handler)

            wd_workers, sys_prog_src_dir, sys_prog_bld_dir = \
                    setup_working_directories(wd_run, general_cfg, sysprog_cfg)

            cpus = args.cpus
            if cpus <= 0:
                raise ValueError(f"Given cpu count must be larger zero but is: {cpus}")
            if args.exact_cpu_map and cpus == 1:
                raise ValueError("Given cpu count must be larger one if "
                                 f"exact_cpu_map is configured but is: {cpus}")

            logger.info(f"Using {cpus} cpus for this run.")

            objective_metric = CodeSizeObjective(Path(tools_cfg["llvm-size"]))
            opt_program = SysProg(tools_cfg, sysprog_cfg, sys_prog_src_dir, sys_prog_bld_dir,
                                  objective_metric, cpus, verbose = args.verbose)
            benchmark_factory = BenchmarkFactory(tools_cfg, benchmark_cfgs, 
                                                 verbose = args.verbose, bfilter = args.bmark_filter)

            # setup function filter
            target_functions = load_target_functions(args.target_functions,
                                    args.fn_chunk_size, args.fn_chunk_offset)
            if target_functions is not None:
                logger.info("Using target function list from " + args.target_functions.name)
                function_filter = InstrumentFunctionList(target_functions)
            else:
                function_filter = InstrumentDefault()

            if args.target_filter:
                target_filter = TargetFilter(args.target_filter)
                logger.info("Using target filter rules from " + args.target_filter.name)
            else:
                target_filter = None

            instr_scope = InstrumentationScope[args.instr_scope]
            instr_chunk = args.instr_chunk

            driver = Driver(
                        main_ctx, tools_cfg, wd_run, wd_workers, opt_program, benchmark_factory,
                        objective_metric, function_filter, target_filter,
                        args.heuristicDB, cpus, instr_scope, instr_chunk,
                        function_cache = args.function_cache, baseline_cache = args.baseline_cache,
                        keep_probes = args.keep_probes, probe_mem_limit=args.probe_mem_limit,
                        worker_mul=args.worker_mul, exact_cpu_map=args.exact_cpu_map,
                        dry_run=args.dry_run, no_instr=args.no_instr,
                        record_exec_log=args.record_exec_log, skip_immutables=args.skip_immutables,
                        independent_test_cases=args.independent_test_cases
                    )

            driver.main_loop()
